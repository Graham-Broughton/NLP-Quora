{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"2.Quora_Feature_Engineering.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyP30HXADnoYZb7JaeSS7hxd"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Imports"],"metadata":{"id":"x6-JjTGYBKPs"}},{"cell_type":"code","source":["!pip install pyemd\n","!pip install fuzzywuzzy\n","!pip install python-Levenshtein"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-tc6euzZC2kw","executionInfo":{"status":"ok","timestamp":1657824600990,"user_tz":420,"elapsed":15392,"user":{"displayName":"graham broughton","userId":"15728648374086258761"}},"outputId":"0209b7bd-e652-4e04-c225-555e98985714"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: pyemd in /usr/local/lib/python3.7/dist-packages (0.5.1)\n","Requirement already satisfied: numpy<2.0.0,>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from pyemd) (1.21.6)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting fuzzywuzzy\n","  Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n","Installing collected packages: fuzzywuzzy\n","Successfully installed fuzzywuzzy-0.18.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting python-Levenshtein\n","  Downloading python-Levenshtein-0.12.2.tar.gz (50 kB)\n","\u001b[K     |████████████████████████████████| 50 kB 4.7 MB/s \n","\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from python-Levenshtein) (57.4.0)\n","Building wheels for collected packages: python-Levenshtein\n","  Building wheel for python-Levenshtein (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for python-Levenshtein: filename=python_Levenshtein-0.12.2-cp37-cp37m-linux_x86_64.whl size=149867 sha256=e5aaac6c82f038811ec79335b7c7de064f0af7349015b8c12e40f4342ec09e17\n","  Stored in directory: /root/.cache/pip/wheels/05/5f/ca/7c4367734892581bb5ff896f15027a932c551080b2abd3e00d\n","Successfully built python-Levenshtein\n","Installing collected packages: python-Levenshtein\n","Successfully installed python-Levenshtein-0.12.2\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import pandas as pd \n","import numpy as np\n","from tqdm import tqdm\n","import pickle\n","import os\n","import regex as re\n","import string\n","from collections import defaultdict, Counter\n","from copy import deepcopy\n","import gc\n","\n","import scipy.stats as stats\n","from scipy import sparse\n","from scipy.spatial.distance import cosine, cityblock, jaccard, canberra, euclidean, minkowski, braycurtis\n","\n","import matplotlib.pyplot as plt\n","from matplotlib import rcParams\n","import seaborn as sns\n","plt.style.use('ggplot')\n","%matplotlib inline\n","\n","import nltk\n","from nltk.corpus import stopwords, wordnet as wn\n","from nltk.stem import WordNetLemmatizer, PorterStemmer\n","from nltk import pos_tag\n","from nltk.tokenize import word_tokenize\n","from fuzzywuzzy import fuzz\n","\n","from sklearn.decomposition import TruncatedSVD\n","from sklearn.model_selection import train_test_split, KFold\n","from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n","from sklearn.metrics import roc_curve, auc, classification_report, confusion_matrix\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.compose import ColumnTransformer\n","from sklearn.pipeline import Pipeline\n","from mlxtend.plotting import plot_confusion_matrix\n","\n","import gensim\n","from gensim import models\n","from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","from drive.MyDrive.Quora_Duplicate_Questions.src.functions import *"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DnWw8Ko6CRtL","executionInfo":{"status":"ok","timestamp":1657824685516,"user_tz":420,"elapsed":7884,"user":{"displayName":"graham broughton","userId":"15728648374086258761"}},"outputId":"4142479e-fc33-4641-f00d-f4a44dcbdf03"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"markdown","source":["# Downloads"],"metadata":{"id":"L0ja-f8_JIpy"}},{"cell_type":"code","source":["def set_seed(seed):\n","    \"\"\"\n","    Sets a global random seed of your choice\n","    \"\"\"\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","set_seed(69)\n","\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","stop_words = set(stopwords.words('english'))\n","\n","PATH = 'drive/MyDrive/Quora_Duplicate_Questions/'\n","data = pd.read_csv(PATH+'src/train.csv', index_col='id')\n","col_list = data.columns.tolist()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5QI7gyvjCs9h","executionInfo":{"status":"ok","timestamp":1657825093531,"user_tz":420,"elapsed":2859,"user":{"displayName":"graham broughton","userId":"15728648374086258761"}},"outputId":"0438c5eb-5b80-40ba-a087-24e8b0754e3c"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]}]},{"cell_type":"markdown","source":["# Fuzzywuzzy Features"],"metadata":{"id":"83A7AhJBJawi"}},{"cell_type":"code","source":["data['fuzz_qratio'] = data.apply(lambda x: fuzz.QRatio(\n","    str(x['question1']), str(x['question2'])), axis=1)\n","data['fuzz_Wratio'] = data.apply(lambda x: fuzz.WRatio(\n","    str(x['question1']), str(x['question2'])), axis=1)\n","\n","data['fuzz_partial_ratio'] = data.apply(lambda x: \n","fuzz.partial_ratio(str(x['question1']), \n","str(x['question2'])), axis=1)\n","\n","data['fuzz_partial_token_set_ratio'] = data.apply(lambda x:\n","fuzz.partial_token_set_ratio(str(x['question1']), \n","str(x['question2'])), axis=1)\n","\n","data['fuzz_partial_token_sort_ratio'] = data.apply(lambda x: \n","fuzz.partial_token_sort_ratio(str(x['question1']), \n","str(x['question2'])), axis=1)\n","\n","data['fuzz_token_set_ratio'] = data.apply(lambda x: \n","fuzz.token_set_ratio(str(x['question1']), \n","str(x['question2'])), axis=1)\n","\n","data['fuzz_token_sort_ratio'] = data.apply(lambda x: \n","                   fuzz.token_sort_ratio(str(x['question1']), \n","                   str(x['question2'])), axis=1)\n","\n","fs_2 = ['fuzz_qratio', 'fuzz_Wratio', 'fuzz_partial_ratio', \n","       'fuzz_partial_token_set_ratio', 'fuzz_partial_token_sort_ratio',\n","       'fuzz_token_set_ratio', 'fuzz_token_sort_ratio']\n","\n","data[fs_2].to_csv(PATH+'src/feat_set_2.csv', index='id')"],"metadata":{"id":"FYfjOHIEDRvS","executionInfo":{"status":"ok","timestamp":1657825686814,"user_tz":420,"elapsed":25467,"user":{"displayName":"graham broughton","userId":"15728648374086258761"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["# TF-idf + Truncated SVD Features"],"metadata":{"id":"th_x9Hk9JlXz"}},{"cell_type":"code","source":["tfv_q1 = TfidfVectorizer(\n","    min_df=3, \n","    max_features=None, \n","    strip_accents='unicode', \n","    analyzer='word', \n","    token_pattern=r'w{1,}',\n","    ngram_range=(1, 2), \n","    use_idf=1, \n","    smooth_idf=1, \n","    sublinear_tf=1,\n","    stop_words='english'\n","    )\n","\n","tfv_q2 = deepcopy(tfv_q1)\n","q1_tfidf = tfv_q1.fit_transform(data['question1'].fillna(\" \"))\n","q2_tfidf = tfv_q2.fit_transform(data['question2'].fillna(\" \"))\n","fs3_1 = sparse.hstack((q1_tfidf, q2_tfidf))"],"metadata":{"id":"y3GUM-VRFFCZ","executionInfo":{"status":"ok","timestamp":1657825771538,"user_tz":420,"elapsed":11017,"user":{"displayName":"graham broughton","userId":"15728648374086258761"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["svd_q1 = TruncatedSVD(n_components=8)\n","svd_q2 = TruncatedSVD(n_components=8)\n","\n","question1_vectors = svd_q1.fit_transform(q1_tfidf)\n","question2_vectors = svd_q2.fit_transform(q2_tfidf)\n","fs3_3 = np.hstack((question1_vectors, question2_vectors))"],"metadata":{"id":"q99KEEiTFaeX","executionInfo":{"status":"ok","timestamp":1657825774164,"user_tz":420,"elapsed":2633,"user":{"displayName":"graham broughton","userId":"15728648374086258761"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["tfv = TfidfVectorizer(min_df=3, \n","                      max_features=None, \n","                      strip_accents='unicode', \n","                      analyzer='word', \n","                      token_pattern=r'w{1,}',\n","                      ngram_range=(1, 2), \n","                      use_idf=1, \n","                      smooth_idf=1, \n","                      sublinear_tf=1,\n","                      stop_words='english')\n","# combine questions and calculate tf-idf\n","q1q2 = data['question1'].fillna(\" \") \n","q1q2 += \" \" + data['question2'].fillna(\" \")\n","fs3_2 = tfv.fit_transform(q1q2)\n","\n","svd_q1q2 = TruncatedSVD(n_components=8)\n","stacks = sparse.hstack((q1_tfidf, q2_tfidf))\n","fs3_4 = svd_q1q2.fit_transform(stacks)\n","fs3_5 = svd_q2.fit_transform(fs3_2)"],"metadata":{"id":"jadgQBQnHZg3","executionInfo":{"status":"ok","timestamp":1657826091164,"user_tz":420,"elapsed":1985,"user":{"displayName":"graham broughton","userId":"15728648374086258761"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["!gzip -d /content/drive/MyDrive/GoogleNews-vectors-negative300.bin.gz"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"spuvLvEsII6p","executionInfo":{"status":"ok","timestamp":1657826780921,"user_tz":420,"elapsed":85396,"user":{"displayName":"graham broughton","userId":"15728648374086258761"}},"outputId":"954fdf3d-9534-4797-f43d-988291b9adc4"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["gzip: /content/GoogleNews-vectors-negative300.bin.gz: No such file or directory\n"]}]},{"cell_type":"code","source":["pickle.dump(fs3_1, open(PATH+'src/fs3_1.pkl', 'wb'))\n","pickle.dump(fs3_2, open(PATH+'src/fs3_2.pkl', 'wb'))\n","pickle.dump(fs3_3, open(PATH+'src/fs3_3.pkl', 'wb'))\n","pickle.dump(fs3_4, open(PATH+'src/fs3_4.pkl', 'wb'))\n","pickle.dump(fs3_5, open(PATH+'src/fs3_5.pkl', 'wb'))"],"metadata":{"id":"gVN9YDMxMT7z","executionInfo":{"status":"ok","timestamp":1657827221731,"user_tz":420,"elapsed":1516,"user":{"displayName":"graham broughton","userId":"15728648374086258761"}}},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":["# GoogleNews Word2Vec Embeddings"],"metadata":{"id":"NrVyBcIILpLg"}},{"cell_type":"code","source":["model = models.KeyedVectors.load_word2vec_format(\n","    '/content/drive/MyDrive/GoogleNews-vectors-negative300.bin', binary=True)\n","\n","gc.collect()\n","\n","def sent2vec(s, model): \n","    M = []\n","    words = word_tokenize(str(s).lower())\n","    for word in words:\n","        #It shouldn't be a stopword\n","        if word not in stop_words:\n","            #nor contain numbers\n","            if word.isalpha():\n","                #and be part of word2vec\n","                if word in model:\n","                    M.append(model[word])\n","    M = np.array(M)\n","    if len(M) > 0:\n","        v = M.sum(axis=0)\n","        return v / np.sqrt((v ** 2).sum())\n","    else:\n","        return np.zeros(300)\n","\n","w2v_q1 = np.array([sent2vec(q, model) \n","                   for q in data.question1])\n","w2v_q2 = np.array([sent2vec(q, model) \n","                   for q in data.question2])\n","\n","w2v = np.hstack((w2v_q1, w2v_q2))"],"metadata":{"id":"zgC_ATM2KU5s","executionInfo":{"status":"ok","timestamp":1657827511222,"user_tz":420,"elapsed":260691,"user":{"displayName":"graham broughton","userId":"15728648374086258761"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["gc.collect()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4_ZXpreIOucM","executionInfo":{"status":"ok","timestamp":1657828029875,"user_tz":420,"elapsed":249,"user":{"displayName":"graham broughton","userId":"15728648374086258761"}},"outputId":"c47fb177-92a1-46d7-d649-72822f876d57"},"execution_count":46,"outputs":[{"output_type":"execute_result","data":{"text/plain":["205"]},"metadata":{},"execution_count":46}]},{"cell_type":"markdown","source":["# Distances"],"metadata":{"id":"tK-3yXOvMAkE"}},{"cell_type":"code","source":["data['cosine_distance'] = [cosine(x,y) \n","for (x,y) in zip(w2v_q1, w2v_q2)]\n","data['cityblock_distance'] = [cityblock(x,y) \n","for (x,y) in zip(w2v_q1, w2v_q2)]\n","data['jaccard_distance'] = [jaccard(x,y) \n","for (x,y) in zip(w2v_q1, w2v_q2)]\n","data['canberra_distance'] = [canberra(x,y) \n","for (x,y) in zip(w2v_q1, w2v_q2)]\n","data['euclidean_distance'] = [euclidean(x,y) \n","for (x,y) in zip(w2v_q1, w2v_q2)]\n","data['minkowski_distance'] = [minkowski(x,y,3) \n","for (x,y) in zip(w2v_q1, w2v_q2)]\n","data['braycurtis_distance'] = [braycurtis(x,y) \n","for (x,y) in zip(w2v_q1, w2v_q2)]\n","\n","fs4_1 = ['cosine_distance', 'cityblock_distance', \n","         'jaccard_distance', 'canberra_distance', \n","         'euclidean_distance', 'minkowski_distance',\n","         'braycurtis_distance']"],"metadata":{"id":"srsSGZrxLhQs","executionInfo":{"status":"ok","timestamp":1657828117845,"user_tz":420,"elapsed":75563,"user":{"displayName":"graham broughton","userId":"15728648374086258761"}}},"execution_count":47,"outputs":[]},{"cell_type":"code","source":["data[fs4_1].to_csv(PATH+'src/fs4_1.csv', index='id')"],"metadata":{"id":"LsYNV4uuNlW0","executionInfo":{"status":"ok","timestamp":1657828290529,"user_tz":420,"elapsed":6301,"user":{"displayName":"graham broughton","userId":"15728648374086258761"}}},"execution_count":48,"outputs":[]},{"cell_type":"code","source":["def wmd(s1, s2, model):\n","    s1 = str(s1).lower().split()\n","    s2 = str(s2).lower().split()\n","    stop_words = stopwords.words('english')\n","    s1 = [w for w in s1 if w not in stop_words]\n","    s2 = [w for w in s2 if w not in stop_words]\n","    return model.wmdistance(s1, s2)\n","\n","data['wmd'] = data.apply(lambda x: wmd(x['question1'], \n","x['question2'], model), axis=1)\n","model.init_sims(replace=True) \n","data['norm_wmd'] = data.apply(lambda x: wmd(x['question1'], \n","x['question2'], model), axis=1)\n","fs4_2 = ['wmd', 'norm_wmd']"],"metadata":{"id":"LCU4emMCNmWy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data[fs4_2].to_csv(PATH'src/fs4_2.csv', index='id')"],"metadata":{"id":"E2uPVVNhREis"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"FKn1e21KRRjM"},"execution_count":null,"outputs":[]}]}